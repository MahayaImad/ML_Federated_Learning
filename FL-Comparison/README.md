# ğŸ”„ Comparaison Apprentissage FÃ©dÃ©rÃ© vs Autres MÃ©thodes

Projet acadÃ©mique pour comparer l'apprentissage fÃ©dÃ©rÃ© avec les approches centralisÃ©es et distribuÃ©es.

## ğŸš€ Installation

```bash
pip install tensorflow numpy matplotlib scikit-learn
```

## ğŸ“ Usage

### Commandes de base

```bash
# FL vs CentralisÃ© sur MNIST
python main.py --dataset mnist --comparison fl_vs_central --epochs 20

# FL vs DistribuÃ© sur CIFAR-10  
python main.py --dataset cifar --comparison fl_vs_distributed --epochs 50

# Comparaison complÃ¨te
python main.py --dataset mnist --comparison all --epochs 30 --verbose --plot

# CPU seulement
python main.py --dataset mnist --comparison fl_vs_central --gpu -1
```

### ParamÃ¨tres disponibles

| ParamÃ¨tre | Description | Valeurs | DÃ©faut |
|-----------|-------------|---------|--------|
| `--dataset` | Dataset Ã  utiliser | `mnist`, `cifar` | **Obligatoire** |
| `--comparison` | Type de comparaison | `fl_vs_central`, `fl_vs_distributed`, `all` | **Obligatoire** |
| `--epochs` | Nombre d'Ã©poques | Entier | 20 |
| `--clients` | Nombre de clients FL | Entier | 5 |
| `--batch_size` | Taille des lots | Entier | 32 |
| `--lr` | Taux d'apprentissage | DÃ©cimal | 0.001 |
| `--iid` | Distribution IID | Flag | False (non-IID) |
| `--gpu` | GPU Ã  utiliser (-1 = CPU) | Entier | 0 |
| `--verbose` | Mode dÃ©taillÃ© | Flag | False |
| `--plot` | Afficher graphiques | Flag | False |

## ğŸ“ Structure des fichiers gÃ©nÃ©rÃ©s

```
FL-Comparison/
â”œâ”€â”€ results/                             # RÃ©sultats dÃ©taillÃ©s (.txt, .json)
â”œâ”€â”€ models/                           # ModÃ¨les entraÃ®nÃ©s (.keras)
â”œâ”€â”€ visualizations/                   # Graphiques de comparaison (.png)
â””â”€â”€ main.py                          # Script principal
```

## ğŸ”¬ Types de comparaisons

### FL vs CentralisÃ©
- **FÃ©dÃ©rÃ©**: EntraÃ®nement distribuÃ© sur plusieurs clients
- **CentralisÃ©**: EntraÃ®nement sur toutes les donnÃ©es rÃ©unies
- **MÃ©triques**: Accuracy, temps, communication

### FL vs DistribuÃ©
- **FÃ©dÃ©rÃ©**: AgrÃ©gation coordonnÃ©e par serveur central
- **DistribuÃ©**: EntraÃ®nement parallÃ¨le sans coordination
- **MÃ©triques**: Convergence, stabilitÃ©, efficacitÃ©

### Comparaison complÃ¨te
- **Tous les types**: FL, CentralisÃ©, DistribuÃ©, variants
- **Analyse complÃ¨te**: Performance, ressources, robustesse

## ğŸ“Š MÃ©triques Ã©valuÃ©es

- **Accuracy finale**: Performance sur le test set
- **Temps d'entraÃ®nement**: EfficacitÃ© computationnelle  
- **CoÃ»t de communication**: Ã‰change de paramÃ¨tres
- **Convergence**: Vitesse et stabilitÃ©
- **Robustesse**: Performance en environnement non-IID

## ğŸ› DÃ©pannage

| ProblÃ¨me | Solution |
|----------|----------|
| Erreur GPU | `--gpu -1` |
| Lent | `--clients 3 --epochs 10` |
| DonnÃ©es dÃ©sÃ©quilibrÃ©es | `--iid` |

## ğŸ“š RÃ©fÃ©rences

1. McMahan et al. "Communication-Efficient Learning of Deep Networks from Decentralized Data"
2. Li et al. "Federated Learning: Challenges, Methods, and Future Directions"
3. Kairouz et al. "Advances and Open Problems in Federated Learning"
