# üîÑ Comparaison Apprentissage F√©d√©r√© vs Autres M√©thodes

Projet acad√©mique pour comparer l'apprentissage f√©d√©r√© avec les approches centralis√©es et distribu√©es.

## üöÄ Installation

```bash
pip install tensorflow numpy matplotlib scikit-learn
```

## üìù Usage

### Commandes de base

```bash
# FL vs Centralis√© sur MNIST
python main.py --dataset mnist --comparison fl_vs_central --epochs 20

# FL vs Distribu√© sur CIFAR-10  
python main.py --dataset cifar --comparison fl_vs_distributed --epochs 50

# Comparaison compl√®te (non-IID, toutes m√©thodes)
python main.py --dataset mnist --comparison all --epochs 25 --verbose --plot

# √âtude impact distribution des donn√©es
python main.py --dataset cifar --comparison all --epochs 30 --iid  # IID
python main.py --dataset cifar --comparison all --epochs 30        # non-IID

# Analyse performance avec plus de clients
python main.py --dataset mnist --comparison all --clients 10 --epochs 20

# CPU seulement
python main.py --dataset mnist --comparison fl_vs_central --gpu -1
```

### Param√®tres disponibles

| Param√®tre | Description | Valeurs | D√©faut |
|-----------|-------------|---------|--------|
| `--dataset` | Dataset √† utiliser | `mnist`, `cifar` | **Obligatoire** |
| `--comparison` | Type de comparaison | `fl_vs_central`, `fl_vs_distributed`, `all` | **Obligatoire** |
| `--epochs` | Nombre d'√©poques | Entier | 20 |
| `--clients` | Nombre de clients FL | Entier | 5 |
| `--batch_size` | Taille des lots | Entier | 32 |
| `--lr` | Taux d'apprentissage | D√©cimal | 0.001 |
| `--iid` | Distribution IID | Flag | False (non-IID) |
| `--gpu` | GPU √† utiliser (-1 = CPU) | Entier | 0 |
| `--verbose` | Mode d√©taill√© | Flag | False |
| `--plot` | Afficher graphiques | Flag | False |

## üìÅ Structure des fichiers g√©n√©r√©s

```
FL-Comparison/
‚îú‚îÄ‚îÄ results/                             # R√©sultats d√©taill√©s (.txt, .json)
‚îú‚îÄ‚îÄ models/                           # Mod√®les entra√Æn√©s (.keras)
‚îú‚îÄ‚îÄ visualizations/                   # Graphiques de comparaison (.png)
‚îî‚îÄ‚îÄ main.py                          # Script principal
```

## ü§ñ M√©thodes FL impl√©ment√©es

### FedAvg (Standard)
- **Description**: Agr√©gation par moyenne pond√©r√©e simple
- **Usage**: Baseline de r√©f√©rence
- **Communication**: Mod√©r√©e

### Cyclic Weighted FL
- **Description**: S√©lection cyclique des clients avec pond√©ration dynamique
- **Avantages**: R√©duction des biais, adaptation √† l'h√©t√©rog√©n√©it√©
- **Communication**: R√©duite (s√©lection partielle)

### Ensemble FL
- **Description**: Multiple mod√®les FL entra√Æn√©s sur des sous-ensembles de clients
- **Avantages**: Robustesse, performance am√©lior√©e
- **Communication**: √âlev√©e (multiples agr√©gations)

## üî¨ Types de comparaisons

### FL vs Centralis√©
- **F√©d√©r√© (FedAvg)**: Entra√Ænement distribu√© avec agr√©gation moyenne
- **Centralis√©**: Entra√Ænement sur toutes les donn√©es r√©unies
- **M√©triques**: Accuracy, temps, communication

### FL vs Distribu√©
- **F√©d√©r√© (FedAvg)**: Agr√©gation coordonn√©e par serveur central
- **Distribu√©**: Entra√Ænement parall√®le sans coordination
- **M√©triques**: Convergence, stabilit√©, efficacit√©

### Comparaison compl√®te (all)
- **Accuracy finale**: Performance sur le test set
- **Temps d'entra√Ænement**: Efficacit√© computationnelle  
- **Co√ªt de communication**: √âchange de param√®tres entre clients/serveur
- **Convergence**: Vitesse et stabilit√© de l'apprentissage
- **Robustesse**: Performance en environnement **non-IID** (d√©faut)
- **Variance**: Stabilit√© entre diff√©rentes ex√©cutions
- **Ensemble metrics**: Diversit√© et consensus des mod√®les (pour FL Ensemble)

## üìä M√©triques √©valu√©es

- **Accuracy finale**: Performance sur le test set
- **Temps d'entra√Ænement**: Efficacit√© computationnelle  
- **Co√ªt de communication**: √âchange de param√®tres
- **Convergence**: Vitesse et stabilit√©
- **Robustesse**: Performance en environnement non-IID


## üêõ D√©pannage

| Probl√®me | Solution |
|----------|----------|
| Erreur GPU | `--gpu -1` |
| Lent | `--clients 3 --epochs 10` |
| Donn√©es d√©s√©quilibr√©es | `--iid` |

## üìö R√©f√©rences

1. McMahan et al. "Communication-Efficient Learning of Deep Networks from Decentralized Data"
2. Li et al. "Federated Learning: Challenges, Methods, and Future Directions"
3. Kairouz et al. "Advances and Open Problems in Federated Learning"
4. Zhang et al. "CyclicFL: A cyclic model pre-training approach to efficient federated learning."
5. Shlezinger et al. "Collaborative inference via ensembles on the edge."
