CIFAR, CNN, Centralized Training, batch_size: 64
Train Loss = [2.002736806869507, 1.5935200452804565, 1.4323184490203857, 1.3367124795913696, 1.2550232410430908, 1.1901475191116333, 1.1324236392974854, 1.083351969718933, 1.035569190979004, 0.9929960370063782, 0.9603846073150635, 0.9317520260810852, 0.8983181118965149, 0.8715920448303223, 0.847239077091217, 0.8191909193992615, 0.7981834411621094, 0.7804220914840698, 0.7588926553726196, 0.7374972105026245, 0.7214072942733765, 0.7031688094139099, 0.6864937543869019, 0.6721644401550293, 0.6556397080421448, 0.6395418643951416, 0.6238022446632385, 0.6060646772384644, 0.596619188785553, 0.5801053643226624, 0.5654350519180298, 0.5546353459358215, 0.5362074971199036, 0.528537929058075, 0.5158843994140625, 0.4990539848804474, 0.48982274532318115, 0.47510483860969543, 0.461952805519104, 0.4513649344444275, 0.43639516830444336, 0.42409399151802063, 0.41446664929389954, 0.4000127613544464, 0.39090394973754883, 0.3763730525970459, 0.36352965235710144, 0.35506442189216614, 0.3413103222846985, 0.3292711079120636]
Val Loss = [1.7335355281829834, 1.5040605068206787, 1.4020285606384277, 1.2895241975784302, 1.2847179174423218, 1.1682415008544922, 1.1278834342956543, 1.101161003112793, 1.0791807174682617, 1.0244622230529785, 1.0965545177459717, 0.986146092414856, 0.9627370238304138, 0.9308180809020996, 0.9131579995155334, 0.9249849319458008, 0.8942349553108215, 0.882827639579773, 0.8847869038581848, 0.887076735496521, 0.867348313331604, 0.8869373202323914, 0.8942714929580688, 0.8637032508850098, 0.8746177554130554, 0.8481088876724243, 0.8806183338165283, 0.8629410266876221, 0.8456279039382935, 0.8627716898918152, 0.905590832233429, 0.8697492480278015, 0.9002962708473206, 0.9057466983795166, 0.9119842052459717, 0.8930935263633728, 0.9320299625396729, 0.9141389727592468, 0.9202530384063721, 0.9567866325378418, 0.9267175793647766, 0.9552741050720215, 0.9617443084716797, 0.9646921753883362, 0.972679853439331, 0.9979752898216248, 1.0328925848007202, 1.020471453666687, 1.0416427850723267, 1.0575155019760132]
Val Accuracy = [0.37929999828338623, 0.45719999074935913, 0.5015000104904175, 0.5468000173568726, 0.5400999784469604, 0.5881999731063843, 0.6035000085830688, 0.6085000038146973, 0.6256999969482422, 0.6380000114440918, 0.6216999888420105, 0.6534000039100647, 0.6654000282287598, 0.6779999732971191, 0.6837999820709229, 0.6769000291824341, 0.6858000159263611, 0.6891999840736389, 0.6898000240325928, 0.692799985408783, 0.7006999850273132, 0.6960999965667725, 0.694100022315979, 0.7038000226020813, 0.7045999765396118, 0.7091000080108643, 0.7027999758720398, 0.7099000215530396, 0.7139000296592712, 0.7107999920845032, 0.6996999979019165, 0.7121000289916992, 0.7056000232696533, 0.7049000263214111, 0.704800009727478, 0.7135999798774719, 0.7041000127792358, 0.7111999988555908, 0.7106999754905701, 0.7045000195503235, 0.7163000106811523, 0.7117000222206116, 0.7092000246047974, 0.7145000100135803, 0.7175999879837036, 0.7113999724388123, 0.7095000147819519, 0.7124999761581421, 0.7168999910354614, 0.7145000100135803]
Final Test Loss = 1.0575155019760132
Final Test Accuracy = 0.7145000100135803
Training Parameters:
  - Epochs: 50
  - Learning Rate: 0.001
  - Momentum: 0.9
  - Batch Size: 64
  - Seed: 42
