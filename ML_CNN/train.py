"""
Script principal pour l'entra√Ænement de mod√®les CNN
Usage: python train.py --dataset mnist --model cnn --epochs 50 --gpu 0
"""

import argparse
import os
import sys
import tensorflow as tf
import numpy as np
import matplotlib

matplotlib.use('Agg')
import matplotlib.pyplot as plt

from models import create_model
from data_loader import load_dataset
from utils import setup_gpu, save_results, print_training_info


def parse_arguments():
    """Parse les arguments de ligne de commande avec des explications d√©taill√©es"""
    parser = argparse.ArgumentParser(
        description='Entra√Ænement de mod√®les CNN sur MNIST/CIFAR-10',
        formatter_class=argparse.RawDescriptionHelpFormatter, # Pour pr√©server le format exact
        epilog="""
Exemples d'utilisation:

  üîπ MNIST avec CNN (recommand√© pour d√©buter):
     python train.py --dataset mnist --model cnn --epochs 10 --gpu 0

  üîπ CIFAR-10 avec CNN (plus avanc√©):
     python train.py --dataset cifar --model cnn --epochs 50 --lr 0.001

  üîπ MNIST avec MLP simple:
     python train.py --dataset mnist --model mlp --epochs 20 --batch_size 128

  üîπ Entra√Ænement CPU seulement:
     python train.py --dataset mnist --model cnn --epochs 10 --gpu -1

  üîπ Configuration compl√®te:
     python train.py --dataset cifar --model cnn --epochs 100 --lr 0.01 --batch_size 64 --gpu 0
        """
    )

    # Arguments obligatoires
    parser.add_argument('--dataset', type=str, required=True,
                        choices=['mnist', 'cifar'],
                        help='Dataset √† utiliser (mnist: images 28x28 N&B, cifar: images 32x32 couleur)')

    parser.add_argument('--model', type=str, required=True,
                        choices=['cnn', 'mlp'],
                        help='Architecture du mod√®le (cnn: r√©seau convolutionnel, mlp: r√©seau dense)')

    # Arguments optionnels avec valeurs par d√©faut
    parser.add_argument('--epochs', type=int, default=10,
                        help='Nombre d\'√©poques d\'entra√Ænement (d√©faut: 10)')

    parser.add_argument('--batch_size', type=int, default=64,
                        help='Taille des lots (d√©faut: 64, augmenter si beaucoup de RAM)')

    parser.add_argument('--lr', type=float, default=0.01,
                        help='Taux d\'apprentissage (d√©faut: 0.01, diminuer si perte oscille)')

    parser.add_argument('--momentum', type=float, default=0.9,
                        help='Momentum pour l\'optimiseur SGD (d√©faut: 0.9)')

    parser.add_argument('--gpu', type=int, default=0,
                        help='GPU √† utiliser (d√©faut: 0, -1 pour CPU uniquement)')

    parser.add_argument('--seed', type=int, default=42,
                        help='Graine al√©atoire pour reproductibilit√© (d√©faut: 42)')

    parser.add_argument('--verbose', action='store_true',
                        help='Mode verbeux avec plus de d√©tails')

    return parser.parse_args()


def main():
    """Fonction principale d'entra√Ænement"""

    # Parse des arguments
    args = parse_arguments()

    # Configuration initiale
    print("D√©marrage de l'entra√Ænement...")
    print_training_info(args)

    # Setup GPU
    setup_gpu(args.gpu)

    # Fixer les graines pour reproductibilit√©
    tf.random.set_seed(args.seed)
    np.random.seed(args.seed)

    # Cr√©er la structure de dossiers FL-MIA
    os.makedirs('results', exist_ok=True)
    os.makedirs('models', exist_ok=True)
    os.makedirs('visualizations', exist_ok=True)

    # Charger les donn√©es
    print(f"Chargement du dataset {args.dataset.upper()}...")
    train_data, test_data, input_shape, num_classes = load_dataset(args.dataset, args.batch_size)

    # Cr√©er le mod√®le
    print(f"Construction du mod√®le {args.model.upper()}...")
    model = create_model(args.model, args.dataset, input_shape, num_classes)

    if args.verbose:
        model.summary()

    # Compiler le mod√®le
    optimizer = tf.keras.optimizers.SGD(learning_rate=args.lr, momentum=args.momentum)
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    # Entra√Ænement
    print(f"D√©but de l'entra√Ænement ({args.epochs} √©poques)...")

    history = model.fit(
        train_data,
        epochs=args.epochs,
        validation_data=test_data,
        verbose=1 if args.verbose else 1
    )

    # √âvaluation finale
    print("√âvaluation finale...")
    test_loss, test_acc = model.evaluate(test_data, verbose=0)

    print(f"‚úÖ Entra√Ænement termin√©!")
    print(f"Accuracy finale: {test_acc * 100:.2f}%")
    print(f"Perte finale: {test_loss:.4f}")

    # Sauvegarder les r√©sultats (format FL-MIA)
    save_results(model, history, args, test_loss, test_acc)

    # Afficher la structure comme FL-MIA
    print(f"\nüìÅ R√©sultats sauvegard√©s:")
    print(f"      results/ - Fichiers de r√©sultas d√©taill√©s")
    print(f"      models/ - Mod√®les entra√Æn√©s (.keras)")
    print(f"      visualizations/ - Graphiques et courbes")


if __name__ == '__main__':
    main()